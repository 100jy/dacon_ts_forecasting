{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq2Seq.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNTfoEQkFMosRqDH4N88pyL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/100jy/dacon_ts_forecasting/blob/main/Seq2Seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyusmuWLCLOq"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VD6aITxrCN2c"
      },
      "source": [
        "!pip install torchcontrib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b1-xV5YCMtF"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torchvision\r\n",
        "import torchvision.transforms as transforms\r\n",
        "from torch.utils.data.dataloader import DataLoader\r\n",
        "from torch.utils.data import Dataset\r\n",
        "import torch.optim.adam\r\n",
        "from torchcontrib.optim import SWA\r\n",
        "import datetime\r\n",
        "import matplotlib.pyplot as plt \r\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJqiSxB-CRRE"
      },
      "source": [
        "\r\n",
        "train = pd.read_csv(\"./drive/MyDrive/데이콘/train.csv\", encoding = 'euc-kr')\r\n",
        "\r\n",
        "# 시간 관련 변수들\r\n",
        "train['DateTime'] = pd.to_datetime(train.DateTime)\r\n",
        "#일자\r\n",
        "train['Date'] = train.DateTime.dt.date\r\n",
        "\r\n",
        "# 요일 혹은 분기정보\r\n",
        "train['DayOfWeek'] = (train.DateTime.dt.weekday)/6\r\n",
        "train['DayOfMon'] = ((train.DateTime).dt.day)/31\r\n",
        "train['Quarter'] = ((train.DateTime).dt.quarter)/4\r\n",
        "\r\n",
        "train['Year'] = ((train.DateTime.dt.year) -2019)\r\n",
        "train['Days'] = (train.DateTime.max() - train.DateTime).dt.days + 1\r\n",
        "\r\n",
        "\r\n",
        "left = train.iloc[:,:5].groupby(train['Date']).sum().reset_index()\r\n",
        "right = train.iloc[:,5:].groupby(train['Date']).mean().reset_index()\r\n",
        "train  = pd.merge(left, right, on='Date')\r\n",
        "\r\n",
        "def log_trans(x):\r\n",
        "  return np.log(1+x)\r\n",
        "\r\n",
        "train['Days'] = log_trans(train['Days'])\r\n",
        "\r\n",
        "\r\n",
        "# ts feature 생성 \r\n",
        "for target in ['사용자', '세션', '신규방문자', '페이지뷰']:\r\n",
        "    train[f'{target}CumSum'] = train[target].cumsum()\r\n",
        "    # log하고 rolling mean\r\n",
        "    train[target] = log_trans(train[target])\r\n",
        "    \r\n",
        "    for k in [3,7,14,21]:\r\n",
        "        train[f'{target}RollingMean{k}'] =  (train[target].rolling(k).mean())\r\n",
        "\r\n",
        "    train[f'{target}RollingStd21'] =  (train[target].rolling(21).std().round(0))\r\n",
        "    train[f'{target}DaysSince10000'] = (train[f'{target}CumSum'] > 10000) * 1\r\n",
        "    train[f'{target}DaysSince100000'] = (train[f'{target}CumSum'] > 100000) * 1\r\n",
        "\r\n",
        "    train[f'{target}RollingMeanDiff2w'] = train[f'{target}RollingMean7'] / (train[f'{target}RollingMean14'] + 1) - 1\r\n",
        "    train[f'{target}RollingMeanDiff3w'] = train[f'{target}RollingMean7'] / (train[f'{target}RollingMean21'] + 1) - 1\r\n",
        "\r\n",
        "\r\n",
        "    train[f'{target}CumSum'] = log_trans(train[target].cumsum())\r\n",
        "    \r\n",
        "    \r\n",
        "train = train.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mz6OfvUNCSaF"
      },
      "source": [
        "def make_data(df, window_size=120):\r\n",
        "  # in 180\r\n",
        "  input_window = window_size\r\n",
        "  # out 61 \r\n",
        "  output_window = 61\r\n",
        "\r\n",
        "  window_x = np.zeros((df.shape[0] - (input_window + output_window), input_window, df.shape[1]-1))\r\n",
        "  window_y = np.zeros((df.shape[0] - (input_window + output_window), output_window, 4))\r\n",
        "\r\n",
        "  for start in range(df.shape[0] - (input_window + output_window)):\r\n",
        "      end = start + input_window    \r\n",
        "      window_x[start,:, :] = df.iloc[start : end, 1: ].values\r\n",
        "      window_y[start,:, :] = df.iloc[end   : end + output_window, 1: 5].values\r\n",
        "\r\n",
        "\r\n",
        "  return window_x, window_y\r\n",
        "\r\n",
        "class DatasetWindows(Dataset):\r\n",
        "  def __init__(self, df):\r\n",
        "    x, y = make_data(df)\r\n",
        "    \r\n",
        "    self.x = torch.tensor(x, dtype=torch.float32).cuda()\r\n",
        "    self.y = torch.tensor(y, dtype=torch.float32).cuda()\r\n",
        "    \r\n",
        "  def __len__(self):\r\n",
        "    return len(self.x)\r\n",
        "    \r\n",
        "  def __getitem__(self, idx):\r\n",
        "    return self.x[idx,...], self.y[idx,...]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33HIkz2wCZ40"
      },
      "source": [
        "class Embedding(nn.Module):\r\n",
        "    def __init__(self, input_size, hidden_size):\r\n",
        "        super(Embedding, self).__init__()\r\n",
        "     \r\n",
        "        self.embedding = nn.Sequential(nn.Linear(49, 32),\r\n",
        "                                       nn.Dropout(0.8),\r\n",
        "                                       nn.ReLU())\r\n",
        "\r\n",
        "    def forward(self, input):\r\n",
        "        embedded = self.embedding(input)\r\n",
        "        return embedded\r\n",
        "\r\n",
        "\r\n",
        "class EncoderRNN(nn.Module):\r\n",
        "    def __init__(self, hidden_size, batch_size=30):\r\n",
        "        super(EncoderRNN, self).__init__()\r\n",
        "        self.hidden_size = hidden_size\r\n",
        "        self.batch_size = batch_size\r\n",
        "        self.embedding = Embedding(output_size, hidden_size)\r\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\r\n",
        "\r\n",
        "    def forward(self, input, hidden):\r\n",
        "        embedded = self.embedding(input)\r\n",
        "        output, hidden = self.gru(embedded, hidden)\r\n",
        "        # B 1 32\r\n",
        "        return output, hidden\r\n",
        "\r\n",
        "    def initHidden(self):\r\n",
        "        return torch.zeros(self.batch_size, 1, self.hidden_size).cuda()\r\n",
        "\r\n",
        "\r\n",
        "class DecoderRNN(nn.Module):\r\n",
        "    def __init__(self, hidden_size, output_size, batch_size=30):\r\n",
        "        super(DecoderRNN, self).__init__()\r\n",
        "        self.hidden_size = hidden_size\r\n",
        "        self.batch_size = batch_size\r\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\r\n",
        "        self.out = nn.Linear(hidden_size, output_size)\r\n",
        "\r\n",
        "    def forward(self, input, hidden):\r\n",
        "        # B x 1 x 4\r\n",
        "        embedded = embedded\r\n",
        "        output = F.relu(embedded)\r\n",
        "        output, hidden = self.gru(output, hidden)\r\n",
        "        output = self.out(output[0])\r\n",
        "        # B x 1 x 4\r\n",
        "        return output, hidden\r\n",
        "\r\n",
        "    def initHidden(self):\r\n",
        "        return torch.zeros(self.batch_size, 1, self.hidden_size, device=device)\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPCaZ0k4CiRl"
      },
      "source": [
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=120, batch_size=30):\r\n",
        "    encoder_hidden = encoder.initHidden()\r\n",
        "\r\n",
        "    encoder_optimizer.zero_grad()\r\n",
        "    decoder_optimizer.zero_grad()\r\n",
        "\r\n",
        "    input_length = input_tensor.size(1)\r\n",
        "    target_length = target_tensor.size(1)\r\n",
        "\r\n",
        "    # B x 120 x 32\r\n",
        "    encoder_outputs = torch.zeros(batch_size, max_length, encoder.hidden_size).cuda()\r\n",
        "\r\n",
        "    loss = 0\r\n",
        "\r\n",
        "    for ei in range(input_length):\r\n",
        "        encoder_output, encoder_hidden = encoder(\r\n",
        "            input_tensor[ei], encoder_hidden)\r\n",
        "        encoder_outputs[:,ei,:] = encoder_output[:, 0, :]\r\n",
        "\r\n",
        "    # x_n을 input으로\r\n",
        "    decoder_input = input_tensor[:4,-1,:]\r\n",
        "    # 마지막 hidden state 값을 initial으로 \r\n",
        "    decoder_hidden = encoder_hidden\r\n",
        "\r\n",
        "    for di in range(target_length):\r\n",
        "        decoder_output, decoder_hidden = decoder(\r\n",
        "            decoder_input, decoder_hidden)\r\n",
        "        decoder_input = decoder_output.detach()  # detach from history as input\r\n",
        "\r\n",
        "        loss += criterion(decoder_output, target_tensor[:,di,:])\r\n",
        "\r\n",
        "    loss.backward()\r\n",
        "\r\n",
        "    encoder_optimizer.step()\r\n",
        "    decoder_optimizer.step()\r\n",
        "\r\n",
        "    return loss.item() / target_length"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCMRHaPkdnyc"
      },
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=100, plot_every=100, learning_rate=0.001):\r\n",
        "    start = time.time()\r\n",
        "    plot_losses = []\r\n",
        "    print_loss_total = 0  # Reset every print_every\r\n",
        "    plot_loss_total = 0  # Reset every plot_every\r\n",
        "\r\n",
        "    encoder_optimizer =  torch.optim.Adam(encoder.parameters(), lr=learning_rate)\r\n",
        "    decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=learning_rate)\r\n",
        "\r\n",
        "    criterion = nn.NLLLoss()\r\n",
        "\r\n",
        "    for epoch in range(num_epochs):\r\n",
        "      for data in dataloader:\r\n",
        "        input_tensor, target_tensor = data\r\n",
        "        loss = train(input_tensor, target_tensor, encoder,\r\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\r\n",
        "        print_loss_total += loss\r\n",
        "        plot_loss_total += loss\r\n",
        "\r\n",
        "      if epoch % 100 == 99:\r\n",
        "          val_loss = get_val_loss()\r\n",
        "          print(f\"{epoch+1} Epochs train MSE: {loss.item():1.5f}, \", f\"{epoch+1} Epochs val MSE: {val_loss:1.5f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MktzJsx9eg58"
      },
      "source": [
        "class ModelManager():\r\n",
        "  def __init__(self, model_name, df, device='gpu', cv=50):\r\n",
        "    super(ModelManager, self).__init__()\r\n",
        "    self.cv = cv\r\n",
        "    # CV 구현..\r\n",
        "    self.models = []\r\n",
        "    self.dataloders = []\r\n",
        "    \r\n",
        "    for i in range(cv):  \r\n",
        "      model =  model_name()\r\n",
        "      if device == 'gpu':\r\n",
        "        model =  model.cuda()\r\n",
        "      self.models.append(model)\r\n",
        "\r\n",
        "      cv_set = df\r\n",
        "      dataset = DatasetWindows(cv_set)\r\n",
        "      self.dataloders.append(DataLoader(dataset, batch_size=30,  num_workers=0, pin_memory=False,\r\n",
        "                                        shuffle=True))\r\n",
        "    \r\n",
        "  def fit(self, num_epochs=500, lr=1e-2 ,log=False, val_set=None, train_set=None):\r\n",
        "    \r\n",
        "    def get_val_loss():\r\n",
        "      val_loss = self.make_val_plot(val_set, train_set, get_loss=True)\r\n",
        "      return val_loss\r\n",
        "\r\n",
        "    for i in tqdm(range(self.cv)):  \r\n",
        "      # Train model\r\n",
        "      model = self.models[i]\r\n",
        "      dataloader = self.dataloders[i]\r\n",
        "      optimizer = torch.optim.Adam(model.parameters(), lr=lr)\r\n",
        "      criterion = nn.MSELoss(size_average = True)\r\n",
        "\r\n",
        "      for epoch in range(num_epochs):\r\n",
        "          for data in dataloader:\r\n",
        "              x, y = data\r\n",
        "              train_pred = model(x)\r\n",
        "              loss = criterion(train_pred, y)\r\n",
        "              optimizer.zero_grad()\r\n",
        "              loss.backward()\r\n",
        "              optimizer.step()\r\n",
        "          if epoch % 100 == 99:\r\n",
        "            if log:\r\n",
        "              if val_set.any().any():\r\n",
        "                val_loss = get_val_loss()\r\n",
        "                print(f\"{epoch+1} Epochs train MSE: {loss.item():1.5f}, \", f\"{epoch+1} Epochs val MSE: {val_loss:1.5f}\")\r\n",
        "              else: \r\n",
        "                print(f\"{epoch+1} Epochs train MSE: {loss.item():1.5f}\")\r\n",
        "\r\n",
        "\r\n",
        "  @staticmethod\r\n",
        "  def inverse_log(x):\r\n",
        "    # 32bit 사용시 단위문제 발생..\r\n",
        "    return (np.exp(x)-1).astype(np.int64)\r\n",
        "\r\n",
        "  def predict(self, df):\r\n",
        "\r\n",
        "    last_observe = df.iloc[-180:,1:]\r\n",
        "    inp_tensor = torch.tensor(last_observe.values, dtype=torch.float32).cuda()\r\n",
        "    inp_tensor = inp_tensor.unsqueeze(0)\r\n",
        "\r\n",
        "    model = self.models[0].eval()\r\n",
        "    prediction = model(inp_tensor)\r\n",
        "    self.models[0] = model.train()\r\n",
        "\r\n",
        "    for i in range(1, self.cv): \r\n",
        "      model = self.models[i].eval()\r\n",
        "      prediction += model(inp_tensor)\r\n",
        "      self.models[i] = model.train()\r\n",
        "    \r\n",
        "    prediction /= self.cv\r\n",
        "    return  self.inverse_log(prediction.cpu().detach().squeeze().numpy())\r\n",
        "\r\n",
        "  def make_val_plot(self, val_df, train_df, get_loss=False):\r\n",
        "    #predict\r\n",
        "    pred = self.predict(train_df)\r\n",
        "    label = self.inverse_log(val_df)\r\n",
        "\r\n",
        "    def dacon_rmse(true, pred):  \r\n",
        "      w0 = 1095.214646\r\n",
        "      w1 = 1086.728535\r\n",
        "      w2 = 268.070707\r\n",
        "      w3 = 24236.194444\r\n",
        "\r\n",
        "      score = (np.sqrt(np.mean(np.square(true[:,0] - pred[:,0]))) / w0 + \r\n",
        "               np.sqrt(np.mean(np.square(true[:,1] - pred[:,1]))) / w1 + \r\n",
        "               np.sqrt(np.mean(np.square(true[:,2] - pred[:,2]))) / w2 + \r\n",
        "               np.sqrt(np.mean(np.square(true[:,3] - pred[:,3]))) / w3  )\r\n",
        "      return score\r\n",
        "\r\n",
        "    if get_loss:\r\n",
        "      return dacon_rmse(label.values, pred)\r\n",
        "\r\n",
        "    for idx, key in enumerate(val_df.columns):\r\n",
        "      plt.plot(figsize=(20,10))\r\n",
        "      plt.plot(label.index,pred[:,idx])\r\n",
        "      plt.plot(label[key])\r\n",
        "      plt.legend(['predict', 'label'])\r\n",
        "      plt.show()\r\n",
        "      \r\n",
        "    loss = dacon_rmse(label.iloc[:,:4].values, pred)\r\n",
        "    print('RMSE : ' + str(loss))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}