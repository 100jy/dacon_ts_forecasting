{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ARmodel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOIznzE2k95NersExzYIWLZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/100jy/dacon_ts_forecasting/blob/main/ARmodel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAU1LKzqRnGI",
        "outputId": "2b7b2fb0-1f22-4cc4-816e-56a9e63286ad"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "el94PHpWRpqI",
        "outputId": "a9f0aeb8-f0fb-413c-c809-a74564383d51"
      },
      "source": [
        "!pip install torchcontrib"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchcontrib in /usr/local/lib/python3.6/dist-packages (0.0.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0j_1HjeRqco"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torchvision\r\n",
        "import torchvision.transforms as transforms\r\n",
        "from torch.utils.data.dataloader import DataLoader\r\n",
        "from torch.utils.data import Dataset\r\n",
        "import torch.optim.adam\r\n",
        "from torchcontrib.optim import SWA\r\n",
        "import datetime\r\n",
        "import matplotlib.pyplot as plt \r\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tEmuDxLRsFB"
      },
      "source": [
        "\r\n",
        "train = pd.read_csv(\"./drive/MyDrive/데이콘/train.csv\", encoding = 'euc-kr')\r\n",
        "\r\n",
        "# 시간 관련 변수들\r\n",
        "date_time = pd.to_datetime(train.DateTime)\r\n",
        "#일자\r\n",
        "train['Date'] = date_time.dt.date\r\n",
        "train = train.groupby(train['Date']).sum().reset_index()  \r\n",
        "\r\n",
        "\r\n",
        "def log_trans(x):\r\n",
        "  return np.log(1+x)\r\n",
        "\r\n",
        "def minmax(x):\r\n",
        "  return (x-x.min())/(x.max()-x.min())\r\n",
        "\r\n",
        "\r\n",
        "for target in ['사용자', '세션', '신규방문자', '페이지뷰']:\r\n",
        "  train[target+'_mean'] = (train[target].rolling(60).mean())\r\n",
        "  train[target+'_std'] = (train[target].rolling(60).std())\r\n",
        "\r\n",
        "\r\n",
        "# 보간해줌\r\n",
        "train.iloc[479,1:] = (train.iloc[477,1:] + train.iloc[480,1:]) // 2\r\n",
        "train.iloc[478,1:] = (train.iloc[477,1:] + train.iloc[479,1:]) // 2\r\n",
        "\r\n",
        "# ts feature 생성 \r\n",
        "for target in ['사용자', '세션', '신규방문자', '페이지뷰']:\r\n",
        "\r\n",
        "    #normalizing\r\n",
        "    train[target] = (train[target] - train[target+'_mean']) / (train[target+'_std'] + 1e-5)\r\n",
        "    train[target+'_mean'] = log_trans(train[target+'_mean'])\r\n",
        "    train[target+'_std'] = log_trans(train[target+'_std'])\r\n",
        "    \r\n",
        "train = train.dropna()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "OU7r4oGjWLoA",
        "outputId": "17f90209-b580-4888-8ef4-4217b57795b6"
      },
      "source": [
        "train"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>사용자</th>\n",
              "      <th>세션</th>\n",
              "      <th>신규방문자</th>\n",
              "      <th>페이지뷰</th>\n",
              "      <th>사용자_mean</th>\n",
              "      <th>사용자_std</th>\n",
              "      <th>세션_mean</th>\n",
              "      <th>세션_std</th>\n",
              "      <th>신규방문자_mean</th>\n",
              "      <th>신규방문자_std</th>\n",
              "      <th>페이지뷰_mean</th>\n",
              "      <th>페이지뷰_std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>2018-11-07</td>\n",
              "      <td>-0.556295</td>\n",
              "      <td>-0.584247</td>\n",
              "      <td>-0.384991</td>\n",
              "      <td>-0.432610</td>\n",
              "      <td>5.160300</td>\n",
              "      <td>4.607746</td>\n",
              "      <td>5.132066</td>\n",
              "      <td>4.561907</td>\n",
              "      <td>3.878811</td>\n",
              "      <td>3.885817</td>\n",
              "      <td>7.059603</td>\n",
              "      <td>6.741687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>2018-11-08</td>\n",
              "      <td>-0.383759</td>\n",
              "      <td>-0.352675</td>\n",
              "      <td>0.001401</td>\n",
              "      <td>-0.468571</td>\n",
              "      <td>5.146040</td>\n",
              "      <td>4.598840</td>\n",
              "      <td>5.118892</td>\n",
              "      <td>4.553833</td>\n",
              "      <td>3.869811</td>\n",
              "      <td>3.883374</td>\n",
              "      <td>7.044077</td>\n",
              "      <td>6.738265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>2018-11-09</td>\n",
              "      <td>-0.374020</td>\n",
              "      <td>-0.355272</td>\n",
              "      <td>-0.162480</td>\n",
              "      <td>-0.229845</td>\n",
              "      <td>5.133148</td>\n",
              "      <td>4.592309</td>\n",
              "      <td>5.107258</td>\n",
              "      <td>4.548561</td>\n",
              "      <td>3.865630</td>\n",
              "      <td>3.883535</td>\n",
              "      <td>7.027093</td>\n",
              "      <td>6.727741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>2018-11-10</td>\n",
              "      <td>-0.348252</td>\n",
              "      <td>-0.372892</td>\n",
              "      <td>0.277985</td>\n",
              "      <td>-0.154622</td>\n",
              "      <td>5.113593</td>\n",
              "      <td>4.569798</td>\n",
              "      <td>5.088625</td>\n",
              "      <td>4.528572</td>\n",
              "      <td>3.866328</td>\n",
              "      <td>3.883715</td>\n",
              "      <td>7.011935</td>\n",
              "      <td>6.718447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>2018-11-11</td>\n",
              "      <td>-0.219710</td>\n",
              "      <td>-0.251182</td>\n",
              "      <td>0.190051</td>\n",
              "      <td>0.441710</td>\n",
              "      <td>5.097628</td>\n",
              "      <td>4.552946</td>\n",
              "      <td>5.072984</td>\n",
              "      <td>4.512766</td>\n",
              "      <td>3.870159</td>\n",
              "      <td>3.884008</td>\n",
              "      <td>6.994514</td>\n",
              "      <td>6.691493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>787</th>\n",
              "      <td>2020-11-04</td>\n",
              "      <td>2.359355</td>\n",
              "      <td>2.389423</td>\n",
              "      <td>2.271748</td>\n",
              "      <td>2.233255</td>\n",
              "      <td>7.821449</td>\n",
              "      <td>6.755353</td>\n",
              "      <td>7.803183</td>\n",
              "      <td>6.743263</td>\n",
              "      <td>6.387665</td>\n",
              "      <td>5.584357</td>\n",
              "      <td>10.959621</td>\n",
              "      <td>10.114925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>788</th>\n",
              "      <td>2020-11-05</td>\n",
              "      <td>1.845771</td>\n",
              "      <td>1.789555</td>\n",
              "      <td>1.629254</td>\n",
              "      <td>1.754383</td>\n",
              "      <td>7.836429</td>\n",
              "      <td>6.781409</td>\n",
              "      <td>7.818108</td>\n",
              "      <td>6.767000</td>\n",
              "      <td>6.407375</td>\n",
              "      <td>5.599400</td>\n",
              "      <td>10.977834</td>\n",
              "      <td>10.137575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>789</th>\n",
              "      <td>2020-11-06</td>\n",
              "      <td>1.258113</td>\n",
              "      <td>1.230108</td>\n",
              "      <td>0.797956</td>\n",
              "      <td>1.134281</td>\n",
              "      <td>7.841165</td>\n",
              "      <td>6.793336</td>\n",
              "      <td>7.822912</td>\n",
              "      <td>6.778599</td>\n",
              "      <td>6.413377</td>\n",
              "      <td>5.604898</td>\n",
              "      <td>10.985730</td>\n",
              "      <td>10.148753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>790</th>\n",
              "      <td>2020-11-07</td>\n",
              "      <td>-0.077260</td>\n",
              "      <td>-0.088545</td>\n",
              "      <td>-0.283087</td>\n",
              "      <td>-0.067939</td>\n",
              "      <td>7.840641</td>\n",
              "      <td>6.793387</td>\n",
              "      <td>7.822338</td>\n",
              "      <td>6.778666</td>\n",
              "      <td>6.411326</td>\n",
              "      <td>5.605585</td>\n",
              "      <td>10.987362</td>\n",
              "      <td>10.148065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>791</th>\n",
              "      <td>2020-11-08</td>\n",
              "      <td>-0.050971</td>\n",
              "      <td>-0.080797</td>\n",
              "      <td>-0.311187</td>\n",
              "      <td>-0.332432</td>\n",
              "      <td>7.839289</td>\n",
              "      <td>6.793141</td>\n",
              "      <td>7.820807</td>\n",
              "      <td>6.778456</td>\n",
              "      <td>6.409160</td>\n",
              "      <td>5.606412</td>\n",
              "      <td>10.985049</td>\n",
              "      <td>10.149016</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>733 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           Date       사용자        세션  ...  신규방문자_std  페이지뷰_mean   페이지뷰_std\n",
              "59   2018-11-07 -0.556295 -0.584247  ...   3.885817   7.059603   6.741687\n",
              "60   2018-11-08 -0.383759 -0.352675  ...   3.883374   7.044077   6.738265\n",
              "61   2018-11-09 -0.374020 -0.355272  ...   3.883535   7.027093   6.727741\n",
              "62   2018-11-10 -0.348252 -0.372892  ...   3.883715   7.011935   6.718447\n",
              "63   2018-11-11 -0.219710 -0.251182  ...   3.884008   6.994514   6.691493\n",
              "..          ...       ...       ...  ...        ...        ...        ...\n",
              "787  2020-11-04  2.359355  2.389423  ...   5.584357  10.959621  10.114925\n",
              "788  2020-11-05  1.845771  1.789555  ...   5.599400  10.977834  10.137575\n",
              "789  2020-11-06  1.258113  1.230108  ...   5.604898  10.985730  10.148753\n",
              "790  2020-11-07 -0.077260 -0.088545  ...   5.605585  10.987362  10.148065\n",
              "791  2020-11-08 -0.050971 -0.080797  ...   5.606412  10.985049  10.149016\n",
              "\n",
              "[733 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbJlizcNSKJI"
      },
      "source": [
        "def make_data(df, window_size=30):\r\n",
        "  # in 180\r\n",
        "  input_window = window_size\r\n",
        "  # out 7\r\n",
        "  output_window = 7\r\n",
        "\r\n",
        "  window_x = np.zeros((df.shape[0] - (input_window + output_window), input_window, df.shape[1]-1))\r\n",
        "  window_y = np.zeros((df.shape[0] - (input_window + output_window), output_window, 12))\r\n",
        "\r\n",
        "  for start in range(df.shape[0] - (input_window + output_window)):\r\n",
        "      end = start + input_window    \r\n",
        "      window_x[start,:, :] = df.iloc[start : end, 1: ].values\r\n",
        "      window_y[start,:, :] = df.iloc[end   : end + output_window, 1: 13].values\r\n",
        "\r\n",
        "\r\n",
        "  return window_x, window_y"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjT8Je3nSMTf"
      },
      "source": [
        "class DatasetWindows(Dataset):\r\n",
        "  def __init__(self, df, input_days):\r\n",
        "\r\n",
        "    x, y = make_data(df, input_days)\r\n",
        "    \r\n",
        "    self.x = torch.tensor(x, dtype=torch.float32).cuda()\r\n",
        "    self.y = torch.tensor(y, dtype=torch.float32).cuda()\r\n",
        "  \r\n",
        "  def __len__(self):\r\n",
        "    return len(self.x)\r\n",
        "    \r\n",
        "  def __getitem__(self, idx):\r\n",
        "    return self.x[idx,...], self.y[idx,...]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sEm0xS5SOaP"
      },
      "source": [
        "# in 61 out 61일\r\n",
        "# B x 61 x 75\r\n",
        "# embedding\r\n",
        "# B x 61 x 4\r\n",
        "class SimpleLinear(nn.Module):\r\n",
        "    def __init__(self, input_days, embedded_dim, hidden_size, num_layers, batch_out_p):\r\n",
        "        super(SimpleLinear, self).__init__()\r\n",
        "\r\n",
        "        self.embedding = nn.Sequential(nn.Linear(12, embedded_dim),\r\n",
        "                                       nn.Dropout(batch_out_p),\r\n",
        "                                       nn.ReLU())\r\n",
        "        \r\n",
        "        self.LSTM = nn.Sequential(nn.LSTM(input_size = input_days,\r\n",
        "                            hidden_size = hidden_size,\r\n",
        "                            num_layers=num_layers,\r\n",
        "                            batch_first=True))\r\n",
        "        \r\n",
        "        self.last = nn.Sequential(nn.Linear(embedded_dim, 12))\r\n",
        "    \r\n",
        "    def forward(self, x_time):\r\n",
        "        x_time = self.embedding(x_time)\r\n",
        "        x_time = x_time.transpose(-2,-1)\r\n",
        "        x_time,_ = self.LSTM(x_time)\r\n",
        "        x_time = x_time[...,-7:]\r\n",
        "        x_time = x_time.transpose(-2,-1)\r\n",
        "        out_time = self.last(x_time)\r\n",
        "        \r\n",
        "        return out_time"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-j_VS_BSPfX"
      },
      "source": [
        "class ModelManager():\r\n",
        "  def __init__(self, model_name, embedded_dim, hidden_size, num_layers, batch_out_p, df, device='gpu', cv=1):\r\n",
        "    super(ModelManager, self).__init__()\r\n",
        "    self.cv = cv\r\n",
        "    # CV 구현..\r\n",
        "    self.models = []\r\n",
        "    self.dataloders = []\r\n",
        "    self.days = [90, 120, 180, 360]\r\n",
        "\r\n",
        "    for i in range(cv):  \r\n",
        "      input_days = self.days[i%len(self.days)]\r\n",
        "      model =  model_name(input_days, embedded_dim, hidden_size, num_layers, batch_out_p)\r\n",
        "      if device == 'gpu':\r\n",
        "        model =  model.cuda()\r\n",
        "      self.models.append(model)\r\n",
        "\r\n",
        "      cv_set = df\r\n",
        "      dataset = DatasetWindows(cv_set, input_days)\r\n",
        "      self.dataloders.append(DataLoader(dataset, batch_size=30,  num_workers=0, pin_memory=False,\r\n",
        "                                        shuffle=True))\r\n",
        "    \r\n",
        "  def fit(self, num_epochs=500, lr=1e-2 ,log=False, val_set=None, train_set=None):\r\n",
        "    \r\n",
        "    def get_val_loss():\r\n",
        "      val_loss = self.make_val_plot(val_set, train_set, get_loss=True)\r\n",
        "      return val_loss\r\n",
        "\r\n",
        "    for i in tqdm(range(self.cv)):  \r\n",
        "      # Train model\r\n",
        "      model = self.models[i]\r\n",
        "      dataloader = self.dataloders[i]\r\n",
        "      adam = torch.optim.Adam(model.parameters(), lr=lr)\r\n",
        "      optimizer = SWA(adam, swa_start=10, swa_freq=5, swa_lr=lr/2)\r\n",
        "      criterion = nn.MSELoss(reduction='mean')\r\n",
        "      running_loss = 0\r\n",
        "\r\n",
        "      for epoch in range(num_epochs):\r\n",
        "          for idx,data in enumerate(dataloader):\r\n",
        "              x, y = data\r\n",
        "              train_pred = model(x)\r\n",
        "              loss = criterion(train_pred, y)\r\n",
        "              optimizer.zero_grad()\r\n",
        "              loss.backward()\r\n",
        "              optimizer.step()\r\n",
        "              running_loss += loss.item()\r\n",
        "          if epoch % 100 == 99:\r\n",
        "            if log:\r\n",
        "              if val_set.any().any():\r\n",
        "                val_loss = get_val_loss()\r\n",
        "                print(f\"{epoch+1} Epochs train MSE: {running_loss/(100*idx):1.5f}, \", f\"{epoch+1} Epochs val MSE: {val_loss:1.5f}\")\r\n",
        "              else: \r\n",
        "                print(f\"{epoch+1} Epochs train MSE: {loss.item():1.5f}\")\r\n",
        "              running_loss = 0\r\n",
        "\r\n",
        "  @staticmethod\r\n",
        "  def inverse_log(x):\r\n",
        "    # 32bit 사용시 단위문제 발생..\r\n",
        "    return np.exp(x)-1\r\n",
        "\r\n",
        "  def predict(self, df):\r\n",
        "    input_days = self.days[0]\r\n",
        "    last_observe = df.iloc[-input_days:,1:]\r\n",
        "    inp_tensor = torch.tensor(last_observe.values, dtype=torch.float32).cuda()\r\n",
        "    inp_tensor = inp_tensor.unsqueeze(0)\r\n",
        "    # normalizing 추가\r\n",
        "    # AR\r\n",
        "    for i in range(61//7 + 1):\r\n",
        "      model = self.models[0].eval()\r\n",
        "      prediction = model(inp_tensor)\r\n",
        "\r\n",
        "      mu_7 = self.inverse_log(prediction[...,[4,6,8,10]].cpu().detach().squeeze().numpy())\r\n",
        "      sigma_7 = self.inverse_log(prediction[...,[5,7,9,11]].cpu().detach().squeeze().numpy())\r\n",
        "      x_7 = prediction[...,:4].cpu().detach().squeeze().numpy()\r\n",
        "\r\n",
        "      if i > 0:\r\n",
        "        mu = np.concatenate((mu, mu_7), axis=0)\r\n",
        "        sigma = np.concatenate((sigma, sigma_7), axis=0)\r\n",
        "        x = np.concatenate((x, x_7), axis=0)\r\n",
        "      else:\r\n",
        "        mu = mu_7\r\n",
        "        sigma = sigma_7\r\n",
        "        x =x_7\r\n",
        "\r\n",
        "      inp_tensor = torch.cat([inp_tensor[:,7:,:], prediction], dim=1)\r\n",
        "      \r\n",
        "    prediction = ((x * sigma) + mu)\r\n",
        "\r\n",
        "    self.models[0] = model.train()\r\n",
        "\r\n",
        "    for i in range(1, self.cv): \r\n",
        "      input_days = self.days[i]\r\n",
        "      last_observe = df.iloc[-input_days:,1:]\r\n",
        "      inp_tensor = torch.tensor(last_observe.values, dtype=torch.float32).cuda()\r\n",
        "      inp_tensor = inp_tensor.unsqueeze(0)\r\n",
        "     \r\n",
        "      for j in range(61//7 + 1):\r\n",
        "        model = self.models[i].eval()\r\n",
        "        prediction = model(inp_tensor)\r\n",
        "        mu_7 = self.inverse_log(prediction[...,[4,6,8,10]].cpu().detach().squeeze().numpy())\r\n",
        "        sigma_7 = self.inverse_log(prediction[...,[5,7,9,11]].cpu().detach().squeeze().numpy())\r\n",
        "        x_7 = prediction[...,:4].cpu().detach().squeeze().numpy()\r\n",
        "        \r\n",
        "        if j > 0:\r\n",
        "          mu = np.concatenate((mu, mu_7), axis=0)\r\n",
        "          sigma_7 = np.concatenate((sigma, sigma_7), axis=0)\r\n",
        "          x_7 = np.concatenate((x, x_7), axis=0)\r\n",
        "\r\n",
        "        else:\r\n",
        "          mu = mu_7\r\n",
        "          sigma = sigma_7\r\n",
        "          x =x_7\r\n",
        "        \r\n",
        "        inp_tensor = torch.cat([inp_tensor[:,7:,:], prediction],dim=1)\r\n",
        "\r\n",
        "      pred = ((x * sigma) + mu)\r\n",
        "      prediction += pred\r\n",
        "      self.models[i] = model.train()\r\n",
        "    \r\n",
        "    prediction /= self.cv\r\n",
        "    return  prediction.astype(np.int64)[:61,:]\r\n",
        "\r\n",
        "  def make_val_plot(self, val_df, train_df, get_loss=False):\r\n",
        "    #predict\r\n",
        "    pred = self.predict(train_df)\r\n",
        "    label = val_df\r\n",
        "\r\n",
        "    def dacon_rmse(true, pred):  \r\n",
        "      w0 = 1095.214646\r\n",
        "      w1 = 1086.728535\r\n",
        "      w2 = 268.070707\r\n",
        "      w3 = 24236.194444\r\n",
        "\r\n",
        "      score = (np.sqrt(np.mean(np.square(true[:,0] - pred[:,0]))) / w0 + \r\n",
        "               np.sqrt(np.mean(np.square(true[:,1] - pred[:,1]))) / w1 + \r\n",
        "               np.sqrt(np.mean(np.square(true[:,2] - pred[:,2]))) / w2 + \r\n",
        "               np.sqrt(np.mean(np.square(true[:,3] - pred[:,3]))) / w3  )\r\n",
        "      return score\r\n",
        "\r\n",
        "    if get_loss:\r\n",
        "      return dacon_rmse(label.values, pred)\r\n",
        "\r\n",
        "    for idx, key in enumerate(val_df.columns):\r\n",
        "      plt.plot(figsize=(20,10))\r\n",
        "      plt.plot(label.index,pred[:,idx])\r\n",
        "      plt.plot(label[key])\r\n",
        "      plt.legend(['predict', 'label'])\r\n",
        "      plt.show()\r\n",
        "      \r\n",
        "    loss = dacon_rmse(label.iloc[:,:4].values, pred)\r\n",
        "    print('RMSE : ' + str(loss))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5acoOEDAUAgg",
        "outputId": "17e69c2c-0fc2-4912-9a77-745eda496a71"
      },
      "source": [
        "# train val split\r\n",
        "train_whole = train\r\n",
        "train_split = train[:-61]\r\n",
        "\r\n",
        "val = train.iloc[-61:, 1:5]\r\n",
        "mu = (np.exp(train.iloc[-61:, [5,7,9,11]])-1).values\r\n",
        "sigma = (np.exp(train.iloc[-61:, [6,8,10,12]])-1).values\r\n",
        "val.iloc[:,:] = ((val.values * sigma) + mu).astype(np.int64)\r\n",
        "\r\n",
        "embedded_dim = 256\r\n",
        "hidden_size = 256\r\n",
        "num_layers = 1\r\n",
        "batch_out_p = 0.3\r\n",
        "\r\n",
        "simple = ModelManager(SimpleLinear, embedded_dim, hidden_size, num_layers, batch_out_p, train_split, cv=1)\r\n",
        "simple.fit(num_epochs=1000, lr=1e-3, log=True, val_set=val, train_set=train_split)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "100 Epochs train MSE: 0.85967,  100 Epochs val MSE: 3.11933\n",
            "200 Epochs train MSE: 0.17689,  200 Epochs val MSE: 3.57001\n",
            "300 Epochs train MSE: 0.04552,  300 Epochs val MSE: 3.48797\n",
            "400 Epochs train MSE: 0.02580,  400 Epochs val MSE: 3.62716\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}